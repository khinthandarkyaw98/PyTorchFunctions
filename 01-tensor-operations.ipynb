{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Assignment 1 - PyTorch\n\n### Five Interesting Functions \n\nPyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab. \n\nPyTorch defines a class called Tensor (torch.Tensor) to store and operate on homogeneous multidimensional rectangular arrays of numbers. PyTorch Tensors are similar to NumPy Arrays, but can also be operated on a CUDA-capable Nvidia GPU. PyTorch supports various sub-types of Tensors.\n\nThe five functions that we are exploring are-\n\n- torch.addmv\n- torch.reshape\n- torch.rsqrt\n- torch.sigmoid\n- torch.narrow\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Import torch and other required modules\nimport torch","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function 1 - torch.addmv(input, mat, vec, *, beta=1, alpha=1, out=None)\n\nPerforms a matrix-vector product of the matrix mat and the vector vec. The vector input is added to the final result.\nIf mat is a (n×m) tensor, vec is a 1-D tensor of size m, then input must be broadcastable with a 1-D tensor of size n and out will be 1-D tensor of size n.\nalpha is a scaling factor on matrix-vector product of the matrix and the vector and beta is a scaling factor on the added tensor input. \n\n\n        output = beta * input + alpha ( matrix @ vector)"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 1 \ninp = torch.randn(2)\nmatrix = torch.randn(2, 3)\nvector = torch.randn(3)\ntorch.addmv(inp, matrix, vector)","execution_count":2,"outputs":[{"data":{"text/plain":"tensor([ 2.5996, -1.3543])"},"execution_count":2,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\nreturns a tensor filled with random numbers from a uniform distribution on the interval [0,1)\nThe shape of the tensor is defined by the variable argument size.\n\nThe output of the above example is as follows.\n\n        output = input + (matrix @ vector)"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 2 \ninp = torch.randn(5)\nmatrix = torch.randn(5,5)\nvector = torch.randn(5)\ntorch.addmv(inp, matrix, vector, beta=0.2, alpha=0.5, out = None)","execution_count":3,"outputs":[{"data":{"text/plain":"tensor([ 1.4801, -1.3287, -0.0154, -1.4125,  0.3948])"},"execution_count":3,"metadata":{},"output_type":"execute_result"}]},{"metadata":{},"cell_type":"markdown","source":"The output of the above example is as follows.\n\n       output = beta * input + alpha ( matrix @ vector)"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 3 \ninp = torch.randn(4)\nmatrix = torch.randn(4,5)\nvector = torch.randn(5)\nbeta = 0.2\nalpha = 0.5\ntorch.addmv(inp, matrix, vector, beta, alpha, out = None)","execution_count":4,"outputs":[{"ename":"TypeError","evalue":"addmv() takes 3 positional arguments but 5 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-9c407aaadfaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: addmv() takes 3 positional arguments but 5 were given"]}]},{"metadata":{},"cell_type":"markdown","source":"TypeError: Beta and alpha values must be inside the function as shown in example 2."},{"metadata":{},"cell_type":"markdown","source":"torch.addmv() can be used to optimize code."},{"metadata":{},"cell_type":"markdown","source":"## Function 2 - torch.reshape(input, shape) → Tensor\n\nReturns a tensor with the same data and number of elements as input, but with the specified shape. \n\nParameters : \n\n        input (Tensor) – the tensor to be reshaped\n        shape (tuple of python:ints) – the new shape\nA single dimension may be -1, in which case it’s inferred from the remaining dimensions and the number of elements in input"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 1 \na = torch.arange(4.)\nprint('a = ', a)\nprint(a.dtype)\nb = torch.reshape(a, (2, 2))\nprint('b = ', b)","execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"a =  tensor([0., 1., 2., 3.])\ntorch.float32\nb =  tensor([[0., 1.],\n        [2., 3.]])\n"}]},{"metadata":{},"cell_type":"markdown","source":"As you see in the above example, 'a' is a 1-D tensor. 'b' is a tensor which has the elements of 'a' with a 2-D shape. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 2 \na = torch.randn(2,2)\nprint('a = ', a)\nb = torch.reshape(a, (4, ))\nprint('b = ', b)","execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"a =  tensor([[-0.4085,  1.8582],\n        [ 0.0029, -0.0504]])\nb =  tensor([-0.4085,  1.8582,  0.0029, -0.0504])\n"}]},{"metadata":{},"cell_type":"markdown","source":"'a' is a 2-D tensor and 'b' is a tensor which has the elements of 'a' with 1-D shape. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 3 \na = torch.randn(2,2)\nprint('a = ', a)\nb = torch.reshape(a, 4)\nprint('b = ', b)","execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"a =  tensor([[ 0.1336, -0.0199],\n        [-0.2126,  0.7387]])\n"},{"ename":"TypeError","evalue":"reshape(): argument 'shape' (position 2) must be tuple of ints, not int","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-f68d519ee57b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: reshape(): argument 'shape' (position 2) must be tuple of ints, not int"]}]},{"metadata":{},"cell_type":"markdown","source":"int is not allowed to pass in reshape(). To solve this, you have to write (4,) which is a tuple of ints."},{"metadata":{},"cell_type":"markdown","source":"tensor.reshape() is used to give a new shape to an array without changing its data. The new shape should be compatible with the original shape."},{"metadata":{},"cell_type":"markdown","source":"## Function 3 - torch.rsqrt(input, out=None) → Tensor\n\nReturns a new tensor with the reciprocal of the square-root of each of the elements of input.\n![image.png](attachment:image.png)\n\nParameters: \n\n        input (Tensor) – the input tensor.\n        \n        out (Tensor, optional) – the output tensor.","attachments":{"image.png":{"image/png":"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"}}},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 1 \na = torch.randn(4)\nprint('a = ', a)\nb = torch.rsqrt(a)\nprint('b = ', b)","execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":"a =  tensor([-1.9497, -0.9157,  1.0021, -1.3434])\nb =  tensor([   nan,    nan, 0.9990,    nan])\n"}]},{"metadata":{},"cell_type":"markdown","source":"NaNvariablePythonassign. NaN , standing for not a number, is a numeric data type used to represent any value that is undefined or unpresentable. For example, 0/0 is undefined as a real number and is, therefore, represented by NaN."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 2 \na = torch.tensor([5., 10.])\nprint('a = ', a)\nb = torch.rsqrt(a)\nprint('b = ', b)","execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"a =  tensor([ 5., 10.])\nb =  tensor([0.4472, 0.3162])\n"}]},{"metadata":{},"cell_type":"markdown","source":"'b' is a tensor with the reciprocal of the square-root of the elements in 'a'. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 3 \na = torch.tensor([5, 10])\nprint('a = ', a)\nb = torch.rsqrt(a)\nprint('b = ', b)","execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"a =  tensor([ 5, 10])\n"},{"ename":"RuntimeError","evalue":"\"rsqrt_cpu\" not implemented for 'Long'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-06ed222c3d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: \"rsqrt_cpu\" not implemented for 'Long'"]}]},{"metadata":{},"cell_type":"markdown","source":"Elements should be floating point datatype as shown in example 2."},{"metadata":{},"cell_type":"markdown","source":"The reciprocal of elements in the tensor can be easily computed by using torch.rsqrt()."},{"metadata":{},"cell_type":"markdown","source":"## Function 4 - torch.sigmoid(input, out=None) → Tensor\n\nReturns a new tensor with the sigmoid of the elements of input.\n![image.png](attachment:image.png)\n\nParameters: \n\n    input (Tensor) – the input tensor.\n\n    out (Tensor, optional) – the output tensor\n","attachments":{"image.png":{"image/png":"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"}}},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 1 \ninp = torch.tensor([2.])\nprint('input = ', inp)\nout = torch.sigmoid(inp)\nprint('output = ', out)","execution_count":11,"outputs":[{"name":"stdout","output_type":"stream","text":"input =  tensor([2.])\noutput =  tensor([0.8808])\n"}]},{"metadata":{},"cell_type":"markdown","source":"Check out the answer by substituting input 2.0 in the above formula. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 2 \ninp = torch.randn(4)\nprint('input = ', inp)\nout = torch.sigmoid(inp)\nprint('output = ', out)","execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":"input =  tensor([-0.7093,  0.3146, -1.3003, -0.7110])\noutput =  tensor([0.3298, 0.5780, 0.2141, 0.3294])\n"}]},{"metadata":{},"cell_type":"markdown","source":"torch.sigmoid() can also be used to compute the sigmoid values of elements in the tensor."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 3 \ninp = torch.randn(4.)\nprint('input = ', inp)\nout = torch.sigmoid(inp)\nprint('output = ', out)","execution_count":13,"outputs":[{"ename":"TypeError","evalue":"randn(): argument 'size' (position 1) must be tuple of ints, not float","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-e8a39334f1b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: randn(): argument 'size' (position 1) must be tuple of ints, not float"]}]},{"metadata":{},"cell_type":"markdown","source":"size of torch.randn must not be float. "},{"metadata":{},"cell_type":"markdown","source":"sigmoid() appears in the output layers of the Deep Learning architectures, and is used for predicting probability based outputs and has been successfully implemented in binary classification problems, logistic regression tasks as well as other neural network applications."},{"metadata":{},"cell_type":"markdown","source":"## Function 5 - torch.narrow(input, dim, start, length) → Tensor\nReturns a new tensor that is a narrowed version of input tensor. The dimension dim is input from start to start + length. The returned tensor and input tensor share the same underlying storage.\n\n\nParameters\n\n        input (Tensor) – the tensor to narrow\n\n        dim (int) – the dimension along which to narrow\n\n        start (int) – the starting dimension\n\n        length (int) – the distance to the ending dimension\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 1 \nx = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint('x = ',x ,'\\n')\ny = torch.narrow(x, 0, 0, 2)\nprint('narrow dimension 0, row-wise starting from 0 to end 0+2-1')\nprint('y = ', y)\nprint('\\n')\nz = torch.narrow(x, 0, 1, 2)\nprint('narrow dimension 0, row-wise starting from 1 to end 1+2-1')\nprint('z =', z)","execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"x =  tensor([[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]]) \n\nnarrow dimension 0, row-wise starting from 0 to end 0+2-1\ny =  tensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\nnarrow dimension 0, row-wise starting from 1 to end 1+2-1\nz = tensor([[4, 5, 6],\n        [7, 8, 9]])\n"}]},{"metadata":{},"cell_type":"markdown","source":"The descriptions used in the code are my assumptions. Please correct me if I suppose is wrong. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 2 \nx = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint('x = ',x ,'\\n')\na = torch.narrow(x, 1, 0, 2)\nprint('narrow dimension 1, column-wise starting from 0 to end 0+2-1')\nprint('a = ', a)\nprint('\\n')\nb = torch.narrow(x, 1, 1, 2)\nprint('narrow dimension 1, column-wise starting from 1 to end 1+2-1')\nprint('b = ', b)","execution_count":11,"outputs":[{"name":"stdout","output_type":"stream","text":"x =  tensor([[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]]) \n\nnarrow dimension 1, column-wise starting from 0 to end 0+2-1\na =  tensor([[1, 2],\n        [4, 5],\n        [7, 8]])\n\n\nnarrow dimension 1, column-wise starting from 1 to end 1+2-1\nb =  tensor([[2, 3],\n        [5, 6],\n        [8, 9]])\n"}]},{"metadata":{},"cell_type":"markdown","source":"The descriptions used in the code are my assumptions. Please correct me if I suppose is wrong. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Example 3 \nx = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint('x = ',x ,'\\n')\na = torch.narrow(x, 2, 0, 2)","execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"x =  tensor([[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]]) \n\n"},{"ename":"IndexError","evalue":"Dimension out of range (expected to be in range of [-2, 1], but got 2)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7afb059f15fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x = '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"]}]},{"metadata":{},"cell_type":"markdown","source":"It is out of range which throws an error. "},{"metadata":{},"cell_type":"markdown","source":"torch.narrow() is a kind of slicing function."},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nWe have reviewed some functions in the notebook. To be honest, this is my first time getting hands-on with PyTorch. Please correct me if my explanation for the functions are wrong.  "},{"metadata":{},"cell_type":"markdown","source":"## Reference Links\n\n* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n* https://medium.com/ai%C2%B3-theory-practice-business/a-beginners-guide-to-numpy-with-sigmoid-relu-and-softmax-activation-functions-25b840a9a272\n* https://en.wikipedia.org/wiki/PyTorch\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"!pip install jovian --upgrade --quiet","execution_count":19,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import jovian","execution_count":9,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"jovian.commit()","execution_count":20,"outputs":[{"data":{"application/javascript":"window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})","text/plain":"<IPython.core.display.Javascript object>"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"[jovian] Attempting to save notebook..\u001b[0m\n[jovian] Updating notebook \"khinthandarkyaw98/01-tensor-operations-b9892\" on https://jovian.ml/\u001b[0m\n[jovian] Uploading notebook..\u001b[0m\n[jovian] Capturing environment..\u001b[0m\n[jovian] Committed successfully! https://jovian.ml/khinthandarkyaw98/01-tensor-operations-b9892\u001b[0m\n"},{"data":{"text/plain":"'https://jovian.ml/khinthandarkyaw98/01-tensor-operations-b9892'"},"execution_count":20,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}